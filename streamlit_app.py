import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
from io import StringIO
import time
import json

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .progress-container { margin: 20px 0; }
    .status-text { color: #666; font-style: italic; }
</style>
""", unsafe_allow_html=True)

# APIé…ç½®
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if 'analysis_progress' not in st.session_state:
    st.session_state.analysis_progress = 0
if 'analysis_status' not in st.session_state:
    st.session_state.analysis_status = "ç­‰å¾…å¼€å§‹"
if 'partial_report' not in st.session_state:
    st.session_state.partial_report = []
if 'cancelled' not in st.session_state:
    st.session_state.cancelled = False

def call_qwen_api(prompt, api_key, timeout=120):
    """è°ƒç”¨APIå¹¶å¢åŠ é‡è¯•æœºåˆ¶"""
    retries = 3
    delay = 5  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    for attempt in range(retries):
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": "qwen-plus",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 2000  # å‡å°‘å•æ¬¡è¿”å›é•¿åº¦ï¼Œé¿å…è¶…æ—¶
            }
            
            response = requests.post(
                QWEN_API_URL,
                headers=headers,
                json=data,
                timeout=timeout
            )
            
            if response.status_code == 200:
                response_json = response.json()
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                else:
                    st.warning(f"APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼ˆå°è¯• {attempt+1}/{retries}ï¼‰")
            else:
                st.warning(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼ˆå°è¯• {attempt+1}/{retries}ï¼‰")
                
        except requests.exceptions.Timeout:
            st.warning(f"APIè¯·æ±‚è¶…æ—¶ï¼ˆå°è¯• {attempt+1}/{retries}ï¼‰")
        except Exception as e:
            st.warning(f"APIè°ƒç”¨é”™è¯¯: {str(e)}ï¼ˆå°è¯• {attempt+1}/{retries}ï¼‰")
            
        time.sleep(delay)
        delay *= 2  # æŒ‡æ•°é€€é¿
    
    return None

def extract_text_from_pdf(file):
    """æå–PDFæ–‡æœ¬"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            page_text = page.extract_text() or ""
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""

def split_into_clauses(text, max_clauses=50):
    """åˆ†å‰²æ¡æ¬¾å¹¶é™åˆ¶æ•°é‡ï¼Œé¿å…å¤„ç†è¿‡å¤šå†…å®¹"""
    patterns = [
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+|$)',
        r'(\d+\.\s+.*?)(?=\d+\.\s+|$)',
        r'(\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+.*?)(?=\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+|$)',
        r'(\([1-9]+\)\s+.*?)(?=\([1-9]+\)\s+|$)',
        r'(ã€[^\ã€‘]+ã€‘\s+.*?)(?=ã€[^\ã€‘]+ã€‘\s+|$)'
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:
            # é™åˆ¶æœ€å¤§æ¡æ¬¾æ•°ï¼Œé¿å…å¤„ç†é‡è¿‡å¤§
            return [clause.strip() for clause in clauses if clause.strip()][:max_clauses]
    
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    paragraphs = [p.strip() for p in paragraphs if p.strip() and len(p) > 10]
    return paragraphs[:max_clauses]

def chinese_text_similarity(text1, text2):
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦"""
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    return SequenceMatcher(None, words1, words2).ratio()

def match_clauses(clauses1, clauses2):
    """åŒ¹é…æ¡æ¬¾"""
    matched_pairs = []
    used_indices = set()
    
    for i, clause1 in enumerate(clauses1):
        best_match = None
        best_ratio = 0.25
        best_j = -1
        
        for j, clause2 in enumerate(clauses2):
            if j not in used_indices:
                ratio = chinese_text_similarity(clause1, clause2)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = clause2
                    best_j = j
        
        if best_match:
            matched_pairs.append((clause1, best_match, best_ratio))
            used_indices.add(best_j)
    
    unmatched1 = [clause for i, clause in enumerate(clauses1) 
                 if i not in [idx for idx, _ in enumerate(matched_pairs)]]
    unmatched2 = [clause for j, clause in enumerate(clauses2) if j not in used_indices]
    
    return matched_pairs, unmatched1, unmatched2

def update_progress(total_steps, current_step, status):
    """æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬"""
    progress = current_step / total_steps
    st.session_state.analysis_progress = progress
    st.session_state.analysis_status = status
    
    # æ›´æ–°UI
    progress_bar = st.progress(progress)
    status_text = st.markdown(f"<p class='status-text'>{status}</p>", unsafe_allow_html=True)
    
    return progress_bar, status_text

def generate_analysis_report(matched_pairs, unmatched1, unmatched2, 
                            filename1, filename2, api_key):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œå¸¦è¿›åº¦è·Ÿè¸ªå’Œéƒ¨åˆ†ç»“æœä¿å­˜"""
    # é‡ç½®ä¼šè¯çŠ¶æ€
    st.session_state.partial_report = []
    st.session_state.analysis_progress = 0
    st.session_state.cancelled = False
    
    # è®¡ç®—æ€»æ­¥éª¤æ•°
    total_steps = (len(matched_pairs) + 
                  len(unmatched1) + 
                  len(unmatched2) + 1)  # +1 æ˜¯æ€»ç»“éƒ¨åˆ†
    current_step = 0
    
    # åˆå§‹åŒ–æŠ¥å‘Š
    report = []
    report.append("="*50)
    report.append(f"æ¡æ¬¾åˆè§„æ€§åˆ†ææŠ¥å‘Š")
    report.append(f"å¯¹æ¯”æ–‡ä»¶: {filename1} ä¸ {filename2}")
    report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("="*50 + "\n")
    
    # æ€»ä½“ç»Ÿè®¡
    report.append(f"åˆ†æç»Ÿè®¡:")
    report.append(f"- {filename1} æ¡æ¬¾æ€»æ•°: {len(matched_pairs) + len(unmatched1)}")
    report.append(f"- {filename2} æ¡æ¬¾æ€»æ•°: {len(matched_pairs) + len(unmatched2)}")
    report.append(f"- åŒ¹é…æ¡æ¬¾å¯¹æ•°: {len(matched_pairs)}")
    report.append(f"- {filename1} ç‹¬æœ‰æ¡æ¬¾æ•°: {len(unmatched1)}")
    report.append(f"- {filename2} ç‹¬æœ‰æ¡æ¬¾æ•°: {len(unmatched2)}\n")
    report.append("-"*50 + "\n")
    
    # ä¿å­˜éƒ¨åˆ†æŠ¥å‘Š
    st.session_state.partial_report = report.copy()
    
    # æ˜¾ç¤ºè¿›åº¦æ¡
    progress_bar, status_text = update_progress(
        total_steps, current_step, "å‡†å¤‡åˆ†æåŒ¹é…æ¡æ¬¾..."
    )
    
    # åŒ¹é…æ¡æ¬¾åˆ†æï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰
    report.append("ä¸€ã€åŒ¹é…æ¡æ¬¾åˆ†æ")
    report.append("-"*50)
    
    for i, (clause1, clause2, ratio) in enumerate(matched_pairs):
        # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
        if st.session_state.cancelled:
            report.append("\n\nåˆ†æå·²å–æ¶ˆï¼Œä»¥ä¸‹æ˜¯éƒ¨åˆ†ç»“æœ...")
            return "\n".join(report)
            
        current_step += 1
        progress_bar, status_text = update_progress(
            total_steps, current_step, 
            f"åˆ†æåŒ¹é…æ¡æ¬¾ {i+1}/{len(matched_pairs)}..."
        )
        
        report.append(f"\nåŒ¹é…å¯¹ {i+1} (ç›¸ä¼¼åº¦: {ratio:.2%})")
        report.append(f"{filename1} æ¡æ¬¾: {clause1[:200]}...")  # æˆªæ–­é•¿æ¡æ¬¾
        report.append(f"{filename2} æ¡æ¬¾: {clause2[:200]}...")
        
        # è°ƒç”¨APIåˆ†æ
        analysis = analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        else:
            report.append("åˆ†æç»“æœ: æ— æ³•è·å–æœ‰æ•ˆåˆ†æï¼ˆAPIè°ƒç”¨å¤±è´¥ï¼‰")
        
        report.append("-"*30)
        
        # ä¿å­˜éƒ¨åˆ†æŠ¥å‘Šï¼Œé˜²æ­¢ä¸­é€”å¤±è´¥ä¸¢å¤±æ‰€æœ‰ç»“æœ
        st.session_state.partial_report = report.copy()
        time.sleep(1)  # é¿å…APIè¯·æ±‚è¿‡äºé¢‘ç¹

    # æœªåŒ¹é…æ¡æ¬¾1åˆ†æ
    report.append("\näºŒã€æœªåŒ¹é…æ¡æ¬¾åˆ†æ")
    report.append("-"*50)
    report.append(f"\n{filename1} ç‹¬æœ‰æ¡æ¬¾:")
    
    for i, clause in enumerate(unmatched1):
        if st.session_state.cancelled:
            report.append("\n\nåˆ†æå·²å–æ¶ˆï¼Œä»¥ä¸‹æ˜¯éƒ¨åˆ†ç»“æœ...")
            return "\n".join(report)
            
        current_step += 1
        progress_bar, status_text = update_progress(
            total_steps, current_step, 
            f"åˆ†æ{filename1}ç‹¬æœ‰æ¡æ¬¾ {i+1}/{len(unmatched1)}..."
        )
        
        report.append(f"\næ¡æ¬¾ {i+1}: {clause[:200]}...")
        analysis = analyze_standalone_clause_with_qwen(clause, filename1, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        else:
            report.append("åˆ†æç»“æœ: æ— æ³•è·å–æœ‰æ•ˆåˆ†æï¼ˆAPIè°ƒç”¨å¤±è´¥ï¼‰")
        
        report.append("-"*30)
        st.session_state.partial_report = report.copy()
        time.sleep(1)

    # æœªåŒ¹é…æ¡æ¬¾2åˆ†æ
    report.append(f"\n{filename2} ç‹¬æœ‰æ¡æ¬¾:")
    
    for i, clause in enumerate(unmatched2):
        if st.session_state.cancelled:
            report.append("\n\nåˆ†æå·²å–æ¶ˆï¼Œä»¥ä¸‹æ˜¯éƒ¨åˆ†ç»“æœ...")
            return "\n".join(report)
            
        current_step += 1
        progress_bar, status_text = update_progress(
            total_steps, current_step, 
            f"åˆ†æ{filename2}ç‹¬æœ‰æ¡æ¬¾ {i+1}/{len(unmatched2)}..."
        )
        
        report.append(f"\næ¡æ¬¾ {i+1}: {clause[:200]}...")
        analysis = analyze_standalone_clause_with_qwen(clause, filename2, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        else:
            report.append("åˆ†æç»“æœ: æ— æ³•è·å–æœ‰æ•ˆåˆ†æï¼ˆAPIè°ƒç”¨å¤±è´¥ï¼‰")
        
        report.append("-"*30)
        st.session_state.partial_report = report.copy()
        time.sleep(1)

    # æ€»ç»“å»ºè®®
    current_step += 1
    progress_bar, status_text = update_progress(
        total_steps, current_step, "ç”Ÿæˆæ€»ä½“æ€»ç»“ä¸å»ºè®®..."
    )
    
    report.append("\nä¸‰ã€æ€»ç»“ä¸å»ºè®®")
    report.append("-"*50)
    
    summary_prompt = f"""
    åŸºäºä»¥ä¸Šå¯¹{filename1}å’Œ{filename2}çš„æ¡æ¬¾å¯¹æ¯”åˆ†æï¼Œè¯·ç»™å‡ºä¸€ä»½æ€»ä½“æ€»ç»“å’Œå»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
    1. ä¸¤ä»½æ–‡ä»¶çš„æ€»ä½“åˆè§„æ€§è¯„ä¼°
    2. ä¸»è¦å†²çªç‚¹æ±‡æ€»
    3. æ•´ä½“ä¿®æ”¹å»ºè®®
    4. é£é™©æç¤º
    """
    summary = call_qwen_api(summary_prompt, api_key)
    if summary:
        report.append(summary)
    else:
        report.append("æ— æ³•ç”Ÿæˆæ€»ç»“åˆ†æï¼Œè¯·æ£€æŸ¥APIè¿æ¥")
    
    return "\n".join(report)

def analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key):
    """åˆ†ææ¡æ¬¾åˆè§„æ€§"""
    # ç¼©çŸ­æç¤ºè¯å’Œæ¡æ¬¾é•¿åº¦ï¼Œé¿å…APIè¶…æ—¶
    prompt = f"""
    åˆ†æä»¥ä¸‹ä¸¤ä¸ªæ¡æ¬¾çš„åˆè§„æ€§ï¼š
    
    {filename1} æ¡æ¬¾ï¼š{clause1[:500]}
    {filename2} æ¡æ¬¾ï¼š{clause2[:500]}
    
    è¯·ç®€è¦åˆ†æï¼š
    1. ç›¸ä¼¼åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. ä¸»è¦å·®å¼‚
    3. æ˜¯å¦å­˜åœ¨å†²çª
    4. ç®€è¦å»ºè®®
    """
    
    return call_qwen_api(prompt, api_key)

def analyze_standalone_clause_with_qwen(clause, doc_name, api_key):
    """åˆ†æç‹¬ç«‹æ¡æ¬¾"""
    prompt = f"""
    åˆ†æä»¥ä¸‹æ¡æ¬¾ï¼š{doc_name} ä¸­çš„æ¡æ¬¾ï¼š{clause[:500]}
    
    è¯·ç®€è¦è¯„ä¼°ï¼š
    1. ä¸»è¦å†…å®¹
    2. æ ¸å¿ƒè¦æ±‚
    3. æ½œåœ¨é—®é¢˜
    4. ç®€è¦å»ºè®®
    """
    
    return call_qwen_api(prompt, api_key)

def get_download_link(text, filename):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    buffer = StringIO()
    buffer.write(text)
    buffer.seek(0)
    b64 = base64.b64encode(buffer.read().encode()).decode()
    return f'<a href="data:text/plain;base64,{b64}" download="{filename}" class="btn btn-primary">ä¸‹è½½åˆ†ææŠ¥å‘Š</a>'

def main():
    st.title("PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·")
    st.write("ä¸Šä¼ ä¸¤ä¸ªPDFæ–‡ä»¶ï¼Œç³»ç»Ÿå°†åˆ†ææ¡æ¬¾åˆè§„æ€§å¹¶ç”ŸæˆæŠ¥å‘Š")
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.subheader("è®¾ç½®")
        api_key = st.text_input("Qwen APIå¯†é’¥", type="password")
        max_clauses = st.slider("æœ€å¤§å¤„ç†æ¡æ¬¾æ•°é‡", 10, 100, 30, 
                               help="å‡å°‘æ­¤æ•°é‡å¯åŠ å¿«åˆ†æé€Ÿåº¦å¹¶é™ä½å¤±è´¥æ¦‚ç‡")
    
    # æ–‡ä»¶ä¸Šä¼ 
    col1, col2 = st.columns(2)
    with col1:
        file1 = st.file_uploader("ä¸Šä¼ ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶", type="pdf", key="file1")
    with col2:
        file2 = st.file_uploader("ä¸Šä¼ ç¬¬äºŒä¸ªPDFæ–‡ä»¶", type="pdf", key="file2")
    
    # åˆ†ææ§åˆ¶
    col1, col2 = st.columns(2)
    with col1:
        start_analysis = st.button("å¼€å§‹åˆ†æ", disabled=not (file1 and file2 and api_key))
    with col2:
        if st.button("å–æ¶ˆåˆ†æ"):
            st.session_state.cancelled = True
    
    if start_analysis:
        try:
            with st.spinner("å‡†å¤‡åˆ†æ..."):
                # æå–æ–‡æœ¬
                text1 = extract_text_from_pdf(file1)
                text2 = extract_text_from_pdf(file2)
                
                if not text1 or not text2:
                    st.error("æ— æ³•ä»PDFä¸­æå–æ–‡æœ¬ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ")
                    return
                
                # åˆ†å‰²æ¡æ¬¾
                clauses1 = split_into_clauses(text1, max_clauses)
                clauses2 = split_into_clauses(text2, max_clauses)
                
                st.info(f"æ¡æ¬¾æå–å®Œæˆ: {file1.name} æ‰¾åˆ° {len(clauses1)} æ¡ï¼Œ{file2.name} æ‰¾åˆ° {len(clauses2)} æ¡")
                
                # åŒ¹é…æ¡æ¬¾
                matched_pairs, unmatched1, unmatched2 = match_clauses(clauses1, clauses2)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = generate_analysis_report(
                matched_pairs, unmatched1, unmatched2,
                file1.name, file2.name, api_key
            )
            
            # æ˜¾ç¤ºç»“æœ
            st.success("åˆ†æå®Œæˆï¼")
            st.markdown(get_download_link(report, "æ¡æ¬¾åˆè§„æ€§åˆ†ææŠ¥å‘Š.txt"), unsafe_allow_html=True)
            
            with st.expander("æŸ¥çœ‹æŠ¥å‘Šé¢„è§ˆ"):
                st.text_area("æŠ¥å‘Šå†…å®¹", report, height=300)
                
        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            
            # æ˜¾ç¤ºå·²ç”Ÿæˆçš„éƒ¨åˆ†æŠ¥å‘Š
            if st.session_state.partial_report:
                st.warning("ä»¥ä¸‹æ˜¯å·²å®Œæˆçš„éƒ¨åˆ†åˆ†æç»“æœï¼š")
                partial_report_text = "\n".join(st.session_state.partial_report)
                st.markdown(get_download_link(partial_report_text, "éƒ¨åˆ†æ¡æ¬¾åˆ†ææŠ¥å‘Š.txt"), unsafe_allow_html=True)
                with st.expander("æŸ¥çœ‹éƒ¨åˆ†æŠ¥å‘Š"):
                    st.text_area("éƒ¨åˆ†æŠ¥å‘Šå†…å®¹", partial_report_text, height=300)

if __name__ == "__main__":
    main()
