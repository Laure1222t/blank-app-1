import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba  # ç”¨äºä¸­æ–‡åˆ†è¯ï¼Œæé«˜åŒ¹é…ç²¾åº¦

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .stFileUploader { width: 100%; }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .compliance-ok { border-left: 4px solid #28a745; }
    .compliance-warning { border-left: 4px solid #ffc107; }
    .compliance-conflict { border-left: 4px solid #dc3545; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
    .comparison-section { border: 1px solid #e6e6e6; border-radius: 8px; padding: 15px; margin-bottom: 20px; }
</style>
""", unsafe_allow_html=True)

# é…ç½®Qwen APIå‚æ•° - ä½¿ç”¨æŒ‡å®šçš„APIé“¾æ¥
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

def call_qwen_api(prompt, api_key):
    """è°ƒç”¨Qwenå¤§æ¨¡å‹APIï¼Œä½¿ç”¨æŒ‡å®šçš„APIé“¾æ¥"""
    if not api_key:
        st.error("Qwen APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨å·¦ä¾§æ è¾“å…¥å¯†é’¥")
        return None
        
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # æ„å»ºç¬¦åˆAPIè¦æ±‚çš„è¯·æ±‚æ•°æ®
        data = {
            "model": "qwen-plus",  # å¯æ ¹æ®éœ€è¦æ›´æ¢ä¸ºå…¶ä»–Qwenæ¨¡å‹å¦‚qwen-max
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "max_tokens": 3000
        }
        
        # ä½¿ç”¨æŒ‡å®šçš„APIé“¾æ¥å‘é€POSTè¯·æ±‚
        response = requests.post(
            QWEN_API_URL,
            headers=headers,
            json=data,
            timeout=60
        )
        
        # æ£€æŸ¥HTTPå“åº”çŠ¶æ€
        if response.status_code != 200:
            st.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text}")
            return None
            
        # è§£æJSONå“åº”
        response_json = response.json()
        
        # æ£€æŸ¥å“åº”ç»“æ„
        if "choices" not in response_json or len(response_json["choices"]) == 0:
            st.error("APIè¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
            return None
            
        return response_json["choices"][0]["message"]["content"]
        
    except requests.exceptions.Timeout:
        st.error("APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•")
        return None
    except Exception as e:
        st.error(f"è°ƒç”¨Qwen APIå¤±è´¥: {str(e)}")
        return None

def extract_text_from_pdf(file):
    """ä»PDFæå–æ–‡æœ¬ï¼Œä¼˜åŒ–ä¸­æ–‡å¤„ç†"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            page_text = page.extract_text() or ""
            # å¤„ç†ä¸­æ–‡ç©ºæ ¼å’Œæ¢è¡Œé—®é¢˜
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""

def split_into_clauses(text):
    """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¡æ¬¾ï¼Œå¢å¼ºä¸­æ–‡æ¡æ¬¾è¯†åˆ«"""
    # å¢å¼ºä¸­æ–‡æ¡æ¬¾æ¨¡å¼è¯†åˆ«
    patterns = [
        # ä¸­æ–‡æ¡æ¬¾å¸¸è§æ ¼å¼
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)',  # ç¬¬ä¸€æ¡ã€ç¬¬äºŒæ¡æ ¼å¼
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+|$)',  # ä¸€ã€äºŒã€ä¸‰ã€æ ¼å¼
        r'(\d+\.\s+.*?)(?=\d+\.\s+|$)',  # 1. 2. 3. æ ¼å¼
        r'(\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+.*?)(?=\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+|$)',  # (ä¸€) (äºŒ) æ ¼å¼
        r'(\([1-9]+\)\s+.*?)(?=\([1-9]+\)\s+|$)',  # (1) (2) æ ¼å¼
        r'(ã€[^\ã€‘]+ã€‘\s+.*?)(?=ã€[^\ã€‘]+ã€‘\s+|$)'  # ã€æ ‡é¢˜ã€‘æ ¼å¼
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:  # ç¡®ä¿æ‰¾åˆ°è¶³å¤Ÿå¤šçš„æ¡æ¬¾
            return [clause.strip() for clause in clauses if clause.strip()]
    
    # æŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ†å‰²æ®µè½
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    paragraphs = [p.strip() for p in paragraphs if p.strip() and len(p) > 10]  # è¿‡æ»¤è¿‡çŸ­å†…å®¹
    return paragraphs

def chinese_text_similarity(text1, text2):
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ï¼Œä½¿ç”¨åˆ†è¯ååŒ¹é…"""
    # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    
    # è®¡ç®—åˆ†è¯åçš„ç›¸ä¼¼åº¦
    return SequenceMatcher(None, words1, words2).ratio()

def match_clauses(clauses1, clauses2):
    """åŒ¹é…ä¸¤ä¸ªæ–‡æ¡£ä¸­çš„ç›¸ä¼¼æ¡æ¬¾ï¼Œä¼˜åŒ–ä¸­æ–‡åŒ¹é…"""
    matched_pairs = []
    used_indices = set()
    
    for i, clause1 in enumerate(clauses1):
        best_match = None
        best_ratio = 0.25  # é™ä½ä¸­æ–‡åŒ¹é…é˜ˆå€¼
        best_j = -1
        
        for j, clause2 in enumerate(clauses2):
            if j not in used_indices:
                # ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
                ratio = chinese_text_similarity(clause1, clause2)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = clause2
                    best_j = j
        
        if best_match:
            matched_pairs.append((clause1, best_match, best_ratio))
            used_indices.add(best_j)
    
    return matched_pairs

def create_download_link(content, filename, text):
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{filename}">{text}</a>'

def analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key):
    """ä½¿ç”¨Qwenå¤§æ¨¡å‹åˆ†ææ¡æ¬¾åˆè§„æ€§ï¼Œä¼˜åŒ–ä¸­æ–‡æç¤ºè¯"""
    # ä¼˜åŒ–ä¸­æ–‡æç¤ºè¯ï¼Œæ›´ç¬¦åˆä¸­æ–‡æ¡æ¬¾åˆ†æåœºæ™¯
    prompt = f"""
    è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä¸¤ä¸ªä¸­æ–‡æ¡æ¬¾çš„åˆè§„æ€§ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦å­˜åœ¨å†²çªï¼š
    
    {filename1} æ¡æ¬¾ï¼š{clause1}
    
    {filename2} æ¡æ¬¾ï¼š{clause2}
    
    è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”¨ä¸­æ–‡è¿›è¡Œè¯¦ç»†åˆ†æï¼š
    1. ç›¸ä¼¼åº¦è¯„ä¼°ï¼šè¯„ä¼°ä¸¤ä¸ªæ¡æ¬¾çš„ç›¸ä¼¼ç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. å·®å¼‚ç‚¹åˆ†æï¼šè¯¦ç»†æŒ‡å‡ºä¸¤ä¸ªæ¡æ¬¾åœ¨è¡¨è¿°ã€èŒƒå›´ã€è¦æ±‚ç­‰æ–¹é¢çš„ä¸»è¦å·®å¼‚
    3. åˆè§„æ€§åˆ¤æ–­ï¼šåˆ¤æ–­æ˜¯å¦å­˜åœ¨å†²çªï¼ˆæ— å†²çª/è½»å¾®å†²çª/ä¸¥é‡å†²çªï¼‰
    4. å†²çªåŸå› ï¼šå¦‚æœå­˜åœ¨å†²çªï¼Œè¯·å…·ä½“è¯´æ˜å†²çªçš„åŸå› å’Œå¯èƒ½å¸¦æ¥çš„å½±å“
    5. å»ºè®®ï¼šé’ˆå¯¹å‘ç°çš„é—®é¢˜ï¼Œç»™å‡ºä¸“ä¸šçš„å¤„ç†å»ºè®®
    
    åˆ†ææ—¶è¯·ç‰¹åˆ«æ³¨æ„ä¸­æ–‡æ³•å¾‹/åˆåŒæ¡æ¬¾ä¸­å¸¸ç”¨è¡¨è¿°çš„ç»†å¾®å·®åˆ«ï¼Œ
    å¦‚"åº”å½“"ä¸"å¿…é¡»"ã€"ä¸å¾—"ä¸"ç¦æ­¢"ã€"å¯ä»¥"ä¸"æœ‰æƒ"ç­‰è¯è¯­çš„åŒºåˆ«ã€‚
    """
    
    return call_qwen_api(prompt, api_key)

def analyze_single_comparison(base_text, compare_text, base_filename, compare_filename, api_key):
    """åˆ†æå•ä¸ªåŸºå‡†æ–‡ä»¶ä¸å¯¹æ¯”æ–‡ä»¶çš„åˆè§„æ€§"""
    with st.spinner(f"æ­£åœ¨åˆ†æ {compare_filename} çš„æ¡æ¬¾ç»“æ„..."):
        base_clauses = split_into_clauses(base_text)
        compare_clauses = split_into_clauses(compare_text)
        
        st.success(f"æ¡æ¬¾åˆ†æå®Œæˆ: {base_filename} è¯†åˆ«å‡º {len(base_clauses)} æ¡æ¡æ¬¾ï¼Œ{compare_filename} è¯†åˆ«å‡º {len(compare_clauses)} æ¡æ¡æ¬¾")
    
    # åŒ¹é…æ¡æ¬¾
    with st.spinner(f"æ­£åœ¨åŒ¹é… {compare_filename} ä¸åŸºå‡†æ–‡ä»¶çš„ç›¸ä¼¼æ¡æ¬¾..."):
        matched_pairs = match_clauses(base_clauses, compare_clauses)
    
    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    st.divider()
    col1, col2, col3 = st.columns(3)
    col1.metric(f"{base_filename} æ¡æ¬¾æ•°", len(base_clauses))
    col2.metric(f"{compare_filename} æ¡æ¬¾æ•°", len(compare_clauses))
    col3.metric("åŒ¹é…æ¡æ¬¾æ•°", len(matched_pairs))
    
    # æ˜¾ç¤ºæ¡æ¬¾å¯¹æ¯”å’Œåˆè§„æ€§åˆ†æ
    st.divider()
    st.subheader(f"ğŸ“Š ä¸ {compare_filename} çš„æ¡æ¬¾åˆè§„æ€§è¯¦ç»†åˆ†æï¼ˆQwenå¤§æ¨¡å‹ï¼‰")
    
    # åˆ†ææ¯ä¸ªåŒ¹é…å¯¹çš„åˆè§„æ€§
    for i, (clause1, clause2, ratio) in enumerate(matched_pairs):
        st.markdown(f"### åŒ¹é…æ¡æ¬¾å¯¹ {i+1}ï¼ˆç›¸ä¼¼åº¦: {ratio:.2%}ï¼‰")
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown(f'<div class="clause-box"><strong>{base_filename} æ¡æ¬¾:</strong><br>{clause1}</div>', unsafe_allow_html=True)
        with col_b:
            st.markdown(f'<div class="clause-box"><strong>{compare_filename} æ¡æ¬¾:</strong><br>{clause2}</div>', unsafe_allow_html=True)
        
        with st.spinner("æ­£åœ¨è°ƒç”¨Qwenå¤§æ¨¡å‹è¿›è¡Œä¸­æ–‡åˆè§„æ€§åˆ†æ..."):
            analysis = analyze_compliance_with_qwen(clause1, clause2, base_filename, compare_filename, api_key)
        
        if analysis:
            st.markdown('<div class="model-response"><strong>Qwenå¤§æ¨¡å‹åˆ†æç»“æœ:</strong><br>' + analysis + '</div>', unsafe_allow_html=True)
        
        st.divider()

# åº”ç”¨ä¸»ç•Œé¢
st.title("ğŸ“„ Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·")
st.markdown("ä¸“ä¸ºä¸­æ–‡æ–‡æ¡£ä¼˜åŒ–çš„æ™ºèƒ½æ¡æ¬¾åˆè§„æ€§åˆ†æç³»ç»Ÿï¼Œæ”¯æŒä¸€å¯¹å¤šæ–‡ä»¶æ¯”å¯¹")

# Qwen APIè®¾ç½®
with st.sidebar:
    st.subheader("Qwen API è®¾ç½®")
    qwen_api_key = st.text_input("è¯·è¾“å…¥Qwen APIå¯†é’¥", type="password")
    st.markdown(f"""
    æç¤ºï¼šAPIå¯†é’¥å¯ä»¥ä»é˜¿é‡Œäº‘DashScopeæ§åˆ¶å°è·å–ã€‚
    å½“å‰ä½¿ç”¨çš„APIç«¯ç‚¹ï¼š`{QWEN_API_URL}`
    """)

with st.form("upload_form"):
    st.subheader("æ–‡ä»¶ä¸Šä¼ åŒº")
    base_file = st.file_uploader("é€‰æ‹©åŸºå‡†PDFæ–‡ä»¶ï¼ˆè¢«æ¯”å¯¹çš„ä¸»æ–‡ä»¶ï¼‰", type=["pdf"])
    compare_files = st.file_uploader("é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªå¯¹æ¯”PDFæ–‡ä»¶", type=["pdf"], accept_multiple_files=True)
    
    submitted = st.form_submit_button("å¼€å§‹åˆè§„æ€§åˆ†æ")

if submitted and base_file and compare_files:
    if not qwen_api_key:
        st.warning("æœªæ£€æµ‹åˆ°Qwen APIå¯†é’¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")
    
    with st.spinner("æ­£åœ¨è§£æåŸºå‡†PDFå†…å®¹ï¼Œè¯·ç¨å€™..."):
        base_text = extract_text_from_pdf(base_file)
        
        if not base_text:
            st.error("æ— æ³•æå–åŸºå‡†æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹ï¼Œè¯·ç¡®è®¤PDFåŒ…å«å¯æå–çš„ä¸­æ–‡æ–‡æœ¬")
        else:
            # å¾ªç¯å¤„ç†æ¯ä¸ªå¯¹æ¯”æ–‡ä»¶
            for i, compare_file in enumerate(compare_files, 1):
                st.markdown(f'## ğŸ” æ¯”å¯¹åˆ†æ {i}/{len(compare_files)}: {base_file.name} vs {compare_file.name}')
                st.markdown('<div class="comparison-section">', unsafe_allow_html=True)
                
                with st.spinner(f"æ­£åœ¨è§£æ {compare_file.name} çš„å†…å®¹..."):
                    compare_text = extract_text_from_pdf(compare_file)
                    
                    if not compare_text:
                        st.error(f"æ— æ³•æå– {compare_file.name} çš„æ–‡æœ¬å†…å®¹ï¼Œè¯·ç¡®è®¤PDFåŒ…å«å¯æå–çš„ä¸­æ–‡æ–‡æœ¬")
                    else:
                        analyze_single_comparison(base_text, compare_text, base_file.name, compare_file.name, qwen_api_key)
                
                st.markdown('</div>', unsafe_allow_html=True)
else:
    if submitted:
        if not base_file:
            st.warning("è¯·ä¸Šä¼ åŸºå‡†PDFæ–‡ä»¶")
        if not compare_files:
            st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªå¯¹æ¯”PDFæ–‡ä»¶")
    else:
        st.info('è¯·ä¸Šä¼ ä¸€ä¸ªåŸºå‡†PDFæ–‡ä»¶å’Œè‡³å°‘ä¸€ä¸ªå¯¹æ¯”PDFæ–‡ä»¶ï¼Œç„¶åç‚¹å‡»"å¼€å§‹åˆè§„æ€§åˆ†æ"æŒ‰é’®')

# æ·»åŠ é¡µè„š
st.divider()
st.markdown("""
<style>
.footer {
    font-size: 0.8rem;
    color: #666;
    text-align: center;
    margin-top: 2rem;
}
</style>
<div class="footer">
    ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…· | åŸºäºQwenå¤§æ¨¡å‹ | æ”¯æŒä¸€å¯¹å¤šæ¯”å¯¹ | ä¼˜åŒ–ä¸­æ–‡æ–‡æ¡£å¤„ç†
</div>
""", unsafe_allow_html=True)
