import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
from io import StringIO

# é¡µé¢è®¾ç½®å’Œæ ·å¼ä¿æŒä¸å˜
st.set_page_config(
    page_title="Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .stFileUploader { width: 100%; }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .compliance-ok { border-left: 4px solid #28a745; }
    .compliance-warning { border-left: 4px solid #ffc107; }
    .compliance-conflict { border-left: 4px solid #dc3545; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
</style>
""", unsafe_allow_html=True)

QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

# åŸæœ‰å‡½æ•°ä¿æŒä¸å˜ï¼ˆcall_qwen_api, extract_text_from_pdfç­‰ï¼‰
def call_qwen_api(prompt, api_key):
    if not api_key:
        st.error("Qwen APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨å·¦ä¾§æ è¾“å…¥å¯†é’¥")
        return None
        
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": "qwen-plus",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "max_tokens": 5000
        }
        
        response = requests.post(
            QWEN_API_URL,
            headers=headers,
            json=data,
            timeout=60
        )
        
        if response.status_code != 200:
            st.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text}")
            return None
            
        response_json = response.json()
        
        if "choices" not in response_json or len(response_json["choices"]) == 0:
            st.error("APIè¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
            return None
            
        return response_json["choices"][0]["message"]["content"]
        
    except requests.exceptions.Timeout:
        st.error("APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•")
        return None
    except Exception as e:
        st.error(f"è°ƒç”¨Qwen APIå¤±è´¥: {str(e)}")
        return None

def extract_text_from_pdf(file):
    try:
        pdf_reader = PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            page_text = page.extract_text() or ""
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""

def split_into_clauses(text):
    patterns = [
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+|$)',
        r'(\d+\.\s+.*?)(?=\d+\.\s+|$)',
        r'(\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+.*?)(?=\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+|$)',
        r'(\([1-9]+\)\s+.*?)(?=\([1-9]+\)\s+|$)',
        r'(ã€[^\ã€‘]+ã€‘\s+.*?)(?=ã€[^\ã€‘]+ã€‘\s+|$)'
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:
            return [clause.strip() for clause in clauses if clause.strip()]
    
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    paragraphs = [p.strip() for p in paragraphs if p.strip() and len(p) > 10]
    return paragraphs

def chinese_text_similarity(text1, text2):
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    return SequenceMatcher(None, words1, words2).ratio()

def match_clauses(clauses1, clauses2):
    matched_pairs = []
    used_indices = set()
    
    for i, clause1 in enumerate(clauses1):
        best_match = None
        best_ratio = 0.25
        best_j = -1
        
        for j, clause2 in enumerate(clauses2):
            if j not in used_indices:
                ratio = chinese_text_similarity(clause1, clause2)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = clause2
                    best_j = j
        
        if best_match:
            matched_pairs.append((clause1, best_match, best_ratio))
            used_indices.add(best_j)
    
    unmatched1 = [clause for i, clause in enumerate(clauses1) 
                 if i not in [idx for idx, _ in enumerate(matched_pairs)]]
    unmatched2 = [clause for j, clause in enumerate(clauses2) if j not in used_indices]
    
    return matched_pairs, unmatched1, unmatched2

def analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key):
    prompt = f"""
    è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä¸¤ä¸ªä¸­æ–‡æ¡æ¬¾çš„åˆè§„æ€§ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦å­˜åœ¨å†²çªï¼š
    
    {filename1} æ¡æ¬¾ï¼š{clause1}
    
    {filename2} æ¡æ¬¾ï¼š{clause2}
    
    è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”¨ä¸­æ–‡è¿›è¡Œè¯¦ç»†åˆ†æï¼š
    1. ç›¸ä¼¼åº¦è¯„ä¼°ï¼šè¯„ä¼°ä¸¤ä¸ªæ¡æ¬¾çš„ç›¸ä¼¼ç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. å·®å¼‚ç‚¹åˆ†æï¼šè¯¦ç»†æŒ‡å‡ºä¸¤ä¸ªæ¡æ¬¾åœ¨è¡¨è¿°ã€èŒƒå›´ã€è¦æ±‚ç­‰æ–¹é¢çš„ä¸»è¦å·®å¼‚
    3. åˆè§„æ€§åˆ¤æ–­ï¼šåˆ¤æ–­æ˜¯å¦å­˜åœ¨å†²çªï¼ˆæ— å†²çª/è½»å¾®å†²çª/ä¸¥é‡å†²çªï¼‰
    4. å†²çªåŸå› ï¼šå¦‚æœå­˜åœ¨å†²çªï¼Œè¯·å…·ä½“è¯´æ˜å†²çªçš„åŸå› å’Œå¯èƒ½å¸¦æ¥çš„å½±å“
    5. å»ºè®®ï¼šé’ˆå¯¹å‘ç°çš„é—®é¢˜ï¼Œç»™å‡ºä¸“ä¸šçš„å¤„ç†å»ºè®®
    
    åˆ†ææ—¶è¯·ç‰¹åˆ«æ³¨æ„ä¸­æ–‡æ³•å¾‹/åˆåŒæ¡æ¬¾ä¸­å¸¸ç”¨è¡¨è¿°çš„ç»†å¾®å·®åˆ«ï¼Œ
    å¦‚"åº”å½“"ä¸"å¿…é¡»"ã€"ä¸å¾—"ä¸"ç¦æ­¢"ã€"å¯ä»¥"ä¸"æœ‰æƒ"ç­‰è¯è¯­çš„åŒºåˆ«ã€‚
    """
    
    return call_qwen_api(prompt, api_key)

def analyze_standalone_clause_with_qwen(clause, doc_name, api_key):
    prompt = f"""
    è¯·åˆ†æä»¥ä¸‹ä¸­æ–‡æ¡æ¬¾çš„å†…å®¹ï¼š
    
    {doc_name} ä¸­çš„æ¡æ¬¾ï¼š{clause}
    
    è¯·ç”¨ä¸­æ–‡è¯„ä¼°è¯¥æ¡æ¬¾çš„ä¸»è¦å†…å®¹ã€æ ¸å¿ƒè¦æ±‚ã€æ½œåœ¨å½±å“å’Œå¯èƒ½å­˜åœ¨çš„é—®é¢˜ï¼Œ
    å¹¶ç»™å‡ºç®€è¦åˆ†æå’Œå»ºè®®ã€‚åˆ†ææ—¶è¯·æ³¨æ„ä¸­æ–‡è¡¨è¿°çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§ã€‚
    """
    
    return call_qwen_api(prompt, api_key)

# æ–°å¢ï¼šç”Ÿæˆåˆ†ææŠ¥å‘Šæ–‡æœ¬
def generate_analysis_report(matched_pairs, unmatched1, unmatched2, 
                            filename1, filename2, api_key):
    report = []
    report.append("="*50)
    report.append(f"æ¡æ¬¾åˆè§„æ€§åˆ†ææŠ¥å‘Š")
    report.append(f"å¯¹æ¯”æ–‡ä»¶: {filename1} ä¸ {filename2}")
    report.append("="*50 + "\n")
    
    # æ€»ä½“ç»Ÿè®¡
    report.append(f"åˆ†æç»Ÿè®¡:")
    report.append(f"- {filename1} æ¡æ¬¾æ€»æ•°: {len(matched_pairs) + len(unmatched1)}")
    report.append(f"- {filename2} æ¡æ¬¾æ€»æ•°: {len(matched_pairs) + len(unmatched2)}")
    report.append(f"- åŒ¹é…æ¡æ¬¾å¯¹æ•°: {len(matched_pairs)}")
    report.append(f"- {filename1} ç‹¬æœ‰æ¡æ¬¾æ•°: {len(unmatched1)}")
    report.append(f"- {filename2} ç‹¬æœ‰æ¡æ¬¾æ•°: {len(unmatched2)}\n")
    report.append("-"*50 + "\n")
    
    # åŒ¹é…æ¡æ¬¾åˆ†æ
    report.append("ä¸€ã€åŒ¹é…æ¡æ¬¾åˆ†æ")
    report.append("-"*50)
    
    for i, (clause1, clause2, ratio) in enumerate(matched_pairs):
        report.append(f"\nåŒ¹é…å¯¹ {i+1} (ç›¸ä¼¼åº¦: {ratio:.2%})")
        report.append(f"{filename1} æ¡æ¬¾: {clause1}")
        report.append(f"{filename2} æ¡æ¬¾: {clause2}")
        
        analysis = analyze_compliance_with_qwen(clause1, clause2, filename1, filename2, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        report.append("-"*30)
    
    # æœªåŒ¹é…æ¡æ¬¾åˆ†æ
    report.append("\näºŒã€æœªåŒ¹é…æ¡æ¬¾åˆ†æ")
    report.append("-"*50)
    
    report.append(f"\n{filename1} ç‹¬æœ‰æ¡æ¬¾:")
    for i, clause in enumerate(unmatched1):
        report.append(f"\næ¡æ¬¾ {i+1}: {clause}")
        analysis = analyze_standalone_clause_with_qwen(clause, filename1, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        report.append("-"*30)
    
    report.append(f"\n{filename2} ç‹¬æœ‰æ¡æ¬¾:")
    for i, clause in enumerate(unmatched2):
        report.append(f"\næ¡æ¬¾ {i+1}: {clause}")
        analysis = analyze_standalone_clause_with_qwen(clause, filename2, api_key)
        if analysis:
            report.append("åˆ†æç»“æœ:")
            report.append(analysis)
        report.append("-"*30)
    
    # æ€»ç»“å»ºè®®
    report.append("\nä¸‰ã€æ€»ç»“ä¸å»ºè®®")
    report.append("-"*50)
    
    summary_prompt = f"""
    åŸºäºä»¥ä¸Šå¯¹{filename1}å’Œ{filename2}çš„æ¡æ¬¾å¯¹æ¯”åˆ†æï¼Œè¯·ç»™å‡ºä¸€ä»½æ€»ä½“æ€»ç»“å’Œå»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
    1. ä¸¤ä»½æ–‡ä»¶çš„æ€»ä½“åˆè§„æ€§è¯„ä¼°
    2. ä¸»è¦å†²çªç‚¹æ±‡æ€»
    3. æ•´ä½“ä¿®æ”¹å»ºè®®
    4. é£é™©æç¤º
    """
    summary = call_qwen_api(summary_prompt, api_key)
    if summary:
        report.append(summary)
    else:
        report.append("æ— æ³•ç”Ÿæˆæ€»ç»“åˆ†æï¼Œè¯·æ£€æŸ¥APIè¿æ¥")
    
    return "\n".join(report)

# æ–°å¢ï¼šç”Ÿæˆä¸‹è½½é“¾æ¥
def get_download_link(text, filename):
    buffer = StringIO()
    buffer.write(text)
    buffer.seek(0)
    b64 = base64.b64encode(buffer.read().encode()).decode()
    return f'<a href="data:text/plain;base64,{b64}" download="{filename}">ä¸‹è½½åˆ†ææŠ¥å‘Š</a>'

# ä¸»ç•Œé¢é€»è¾‘
def main():
    st.title("Qwen ä¸­æ–‡PDFæ¡æ¬¾åˆè§„æ€§åˆ†æå·¥å…·")
    st.write("ä¸Šä¼ ä¸¤ä¸ªPDFæ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†ææ¡æ¬¾åˆè§„æ€§å¹¶ç”ŸæˆæŠ¥å‘Š")
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.subheader("è®¾ç½®")
        api_key = st.text_input("Qwen APIå¯†é’¥", type="password")
        auto_generate = st.checkbox("è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š", value=True)
    
    # æ–‡ä»¶ä¸Šä¼ 
    col1, col2 = st.columns(2)
    with col1:
        file1 = st.file_uploader("ä¸Šä¼ ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶", type="pdf", key="file1")
    with col2:
        file2 = st.file_uploader("ä¸Šä¼ ç¬¬äºŒä¸ªPDFæ–‡ä»¶", type="pdf", key="file2")
    
    # åˆ†ææŒ‰é’®
    if st.button("å¼€å§‹åˆ†æ") and file1 and file2 and api_key:
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š..."):
            # æå–æ–‡æœ¬
            text1 = extract_text_from_pdf(file1)
            text2 = extract_text_from_pdf(file2)
            
            # åˆ†å‰²æ¡æ¬¾
            clauses1 = split_into_clauses(text1)
            clauses2 = split_into_clauses(text2)
            
            # åŒ¹é…æ¡æ¬¾
            matched_pairs, unmatched1, unmatched2 = match_clauses(clauses1, clauses2)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = generate_analysis_report(
                matched_pairs, unmatched1, unmatched2,
                file1.name, file2.name, api_key
            )
            
            # æ˜¾ç¤ºæŠ¥å‘Šä¸‹è½½é“¾æ¥
            st.success("åˆ†æå®Œæˆï¼")
            st.markdown(get_download_link(report, "æ¡æ¬¾åˆè§„æ€§åˆ†ææŠ¥å‘Š.txt"), unsafe_allow_html=True)
            
            # å¯é€‰ï¼šç®€è¦å±•ç¤ºæŠ¥å‘Šå†…å®¹
            with st.expander("ç‚¹å‡»æŸ¥çœ‹æŠ¥å‘Šé¢„è§ˆ"):
                st.text_area("æŠ¥å‘Šå†…å®¹", report, height=400)

if __name__ == "__main__":
    main()
